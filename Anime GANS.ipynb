{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import os,scipy.misc\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['KERAS_BACKEND']='tensorflow' \n",
    "os.environ['TENSORFLOW_FLAGS']='floatX=float32,device=gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02)\n",
    "\n",
    "\n",
    "def DCGAN_D(isize, nc, ndf):\n",
    "    inputs = Input(shape=(isize, isize, nc))\n",
    "    x = ZeroPadding2D()(inputs)\n",
    "    x = Conv2D(ndf, kernel_size=4, strides=2, use_bias=False, kernel_initializer=conv_init)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    for _ in range(4):\n",
    "        x = ZeroPadding2D()(x)\n",
    "        x = Conv2D(ndf*2, kernel_size=4, strides=2, use_bias=False, kernel_initializer=conv_init)(x)\n",
    "        x = BatchNormalization(epsilon=1.01e-5, gamma_init=gamma_init)(x, training=1)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        ndf *= 2    \n",
    "    x = Conv2D(1, kernel_size=3, strides=1, use_bias=False, kernel_initializer=conv_init)(x)\n",
    "    outputs = Flatten()(x)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def DCGAN_G(isize, nz, ngf):\n",
    "    inputs = Input(shape=(nz,))\n",
    "    x = Reshape((1, 1, nz))(inputs)\n",
    "    x = Conv2DTranspose(filters=ngf, kernel_size=3, strides=2, use_bias=False,\n",
    "                           kernel_initializer = conv_init)(x)\n",
    "    for _ in range(4):\n",
    "        x = Conv2DTranspose(filters=int(ngf/2), kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init)(x)\n",
    "        x = Cropping2D(cropping=1)(x)\n",
    "        x = BatchNormalization(epsilon=1.01e-5, gamma_init=gamma_init)(x, training=1) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        ngf = int(ngf/2)\n",
    "    x = Conv2DTranspose(filters=3, kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init)(x)\n",
    "    x = Cropping2D(cropping=1)(x)\n",
    "    outputs = Activation(\"tanh\")(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 98, 98, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        3072      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 256)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 1024)        8388608   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 1)           9216      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 11,161,088\n",
      "Trainable params: 11,157,248\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 3, 3, 1024)        921600    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 512)         8388608   \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 14, 14, 256)       2097152   \n",
      "_________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 26, 26, 128)       524288    \n",
      "_________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 50, 50, 64)        131072    \n",
      "_________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 98, 98, 3)         3072      \n",
      "_________________________________________________________________\n",
      "cropping2d_5 (Cropping2D)    (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 96, 96, 3)         0         \n",
      "=================================================================\n",
      "Total params: 12,069,632\n",
      "Trainable params: 12,067,712\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nc = 3\n",
    "nz = 100\n",
    "ngf = 1024\n",
    "ndf = 64\n",
    "imageSize = 96\n",
    "batchSize = 64\n",
    "lrD = 0.00005 \n",
    "lrG = 0.00005\n",
    "clamp_lower, clamp_upper = -0.01, 0.01  \n",
    "\n",
    "netD = DCGAN_D(imageSize, nc, ndf)\n",
    "netD.summary()\n",
    "\n",
    "netG = DCGAN_G(imageSize, nz, ngf)\n",
    "netG.summary()\n",
    "\n",
    "clamp_updates = [K.update(v, K.clip(v, clamp_lower, clamp_upper))\n",
    "                          for v in netD.trainable_weights]\n",
    "netD_clamp = K.function([],[], clamp_updates)\n",
    "\n",
    "netD_real_input = Input(shape=(imageSize, imageSize, nc))\n",
    "noisev = Input(shape=(nz,))\n",
    "\n",
    "loss_real = K.mean(netD(netD_real_input))\n",
    "loss_fake = K.mean(netD(netG(noisev)))\n",
    "loss = loss_fake - loss_real \n",
    "training_updates = RMSprop(lr=lrD).get_updates(netD.trainable_weights,[], loss)\n",
    "netD_train = K.function([netD_real_input, noisev],\n",
    "                        [loss_real, loss_fake],    \n",
    "                        training_updates)\n",
    "\n",
    "loss = -loss_fake \n",
    "training_updates = RMSprop(lr=lrG).get_updates(netG.trainable_weights,[], loss)\n",
    "netG_train = K.function([noisev], [loss], training_updates)\n",
    "\n",
    "fixed_noise = np.random.normal(size=(batchSize, nz)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70171 images belonging to 1 classes.\n",
      "[0] Loss_D: 0.025710 Loss_G: 0.006874 Loss_D_real: 0.018629 Loss_D_fake -0.007080\n",
      "[1] Loss_D: 0.035892 Loss_G: 0.004455 Loss_D_real: 0.031417 Loss_D_fake -0.004476\n",
      "[2] Loss_D: 0.046441 Loss_G: 0.002230 Loss_D_real: 0.044172 Loss_D_fake -0.002269\n",
      "[3] Loss_D: 0.061715 Loss_G: 0.002235 Loss_D_real: 0.061341 Loss_D_fake -0.000374\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=20,rescale=1./255)\n",
    "\n",
    "train_generate = datagen.flow_from_directory(\"faces/\", target_size=(96,96), batch_size=64, \n",
    "                                                shuffle=True, class_mode=None, save_format='jpg')\n",
    "\n",
    "step = 0\n",
    "for step in range(5):   \n",
    "    \n",
    "    for datagen in range(5):\n",
    "        real_data = (np.array(train_generate.next())*2-1)\n",
    "        noise = np.random.normal(size=(batchSize, nz))\n",
    "        errD_real, errD_fake  = netD_train([real_data, noise])\n",
    "        errD = errD_real - errD_fake\n",
    "        netD_clamp([])\n",
    "    \n",
    "    noise = np.random.normal(size=(batchSize, nz))  \n",
    "    errG, = netG_train([noise])    \n",
    "    print('[%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f' % (step, errD, errG, errD_real, errD_fake))\n",
    "            \n",
    "    if step%5==0:\n",
    "        netD.save(\"discriminator.h5\")\n",
    "        netG.save(\"generate.h5\")\n",
    "        fake = netG.predict(fixed_noise)\n",
    "        display_grid = np.zeros((8*96,8*96,3))\n",
    "        \n",
    "        for j in range(int(64/8)):\n",
    "            for k in range(int(64/8)):\n",
    "                display_grid[j*96:(j+1)*96,k*96:(k+1)*96,:] = fake[k+8*j]\n",
    "        img_save_path = os.path.join(os.getcwd(),\"saved/img/{}.png\".format(step))\n",
    "        scipy.misc.imsave(img_save_path, display_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
