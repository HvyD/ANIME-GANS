{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import os,scipy.misc\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Input\n",
    "from keras.layers import Conv2DTranspose, Reshape, Activation, Cropping2D, Flatten\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.environ['KERAS_BACKEND']='tensorflow' \n",
    "os.environ['TENSORFLOW_FLAGS']='floatX=float32,device=gpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_init = RandomNormal(0, 0.02)\n",
    "gamma_init = RandomNormal(1., 0.02)\n",
    "\n",
    "\n",
    "def DCGAN_D(isize, nc, ndf):\n",
    "    inputs = Input(shape=(isize, isize, nc))\n",
    "    x = ZeroPadding2D()(inputs)\n",
    "    x = Conv2D(ndf, kernel_size=4, strides=2, use_bias=False, kernel_initializer=conv_init)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    for _ in range(4):\n",
    "        x = ZeroPadding2D()(x)\n",
    "        x = Conv2D(ndf*2, kernel_size=4, strides=2, use_bias=False, kernel_initializer=conv_init)(x)\n",
    "        x = BatchNormalization(epsilon=1.01e-5, gamma_init=gamma_init)(x, training=1)\n",
    "        x = LeakyReLU(alpha=0.2)(x)\n",
    "        ndf *= 2    \n",
    "    x = Conv2D(1, kernel_size=3, strides=1, use_bias=False, kernel_initializer=conv_init)(x)\n",
    "    outputs = Flatten()(x)\n",
    "    return Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "def DCGAN_G(isize, nz, ngf):\n",
    "    inputs = Input(shape=(nz,))\n",
    "    x = Reshape((1, 1, nz))(inputs)\n",
    "    x = Conv2DTranspose(filters=ngf, kernel_size=3, strides=2, use_bias=False,\n",
    "                           kernel_initializer = conv_init)(x)\n",
    "    for _ in range(4):\n",
    "        x = Conv2DTranspose(filters=int(ngf/2), kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init)(x)\n",
    "        x = Cropping2D(cropping=1)(x)\n",
    "        x = BatchNormalization(epsilon=1.01e-5, gamma_init=gamma_init)(x, training=1) \n",
    "        x = Activation(\"relu\")(x)\n",
    "        ngf = int(ngf/2)\n",
    "    x = Conv2DTranspose(filters=3, kernel_size=4, strides=2, use_bias=False,\n",
    "                        kernel_initializer = conv_init)(x)\n",
    "    x = Cropping2D(cropping=1)(x)\n",
    "    outputs = Activation(\"tanh\")(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 98, 98, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        3072      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 50, 50, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 256)       524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         2097152   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 3, 1024)        8388608   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 1, 1, 1)           9216      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 11,161,088\n",
      "Trainable params: 11,157,248\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 3, 3, 1024)        921600    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 8, 8, 512)         8388608   \n",
      "_________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 14, 14, 256)       2097152   \n",
      "_________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 26, 26, 128)       524288    \n",
      "_________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 50, 50, 64)        131072    \n",
      "_________________________________________________________________\n",
      "cropping2d_4 (Cropping2D)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 98, 98, 3)         3072      \n",
      "_________________________________________________________________\n",
      "cropping2d_5 (Cropping2D)    (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 96, 96, 3)         0         \n",
      "=================================================================\n",
      "Total params: 12,069,632\n",
      "Trainable params: 12,067,712\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nc = 3\n",
    "nz = 100\n",
    "ngf = 1024\n",
    "ndf = 64\n",
    "imageSize = 96\n",
    "batchSize = 64\n",
    "lrD = 0.00005 \n",
    "lrG = 0.00005\n",
    "clamp_lower, clamp_upper = -0.01, 0.01  \n",
    "\n",
    "netD = DCGAN_D(imageSize, nc, ndf)\n",
    "netD.summary()\n",
    "\n",
    "netG = DCGAN_G(imageSize, nz, ngf)\n",
    "netG.summary()\n",
    "\n",
    "clamp_updates = [K.update(v, K.clip(v, clamp_lower, clamp_upper))\n",
    "                          for v in netD.trainable_weights]\n",
    "netD_clamp = K.function([],[], clamp_updates)\n",
    "\n",
    "netD_real_input = Input(shape=(imageSize, imageSize, nc))\n",
    "noisev = Input(shape=(nz,))\n",
    "\n",
    "loss_real = K.mean(netD(netD_real_input))\n",
    "loss_fake = K.mean(netD(netG(noisev)))\n",
    "loss = loss_fake - loss_real \n",
    "training_updates = RMSprop(lr=lrD).get_updates(netD.trainable_weights,[], loss)\n",
    "netD_train = K.function([netD_real_input, noisev],\n",
    "                        [loss_real, loss_fake],    \n",
    "                        training_updates)\n",
    "\n",
    "loss = -loss_fake \n",
    "training_updates = RMSprop(lr=lrG).get_updates(netG.trainable_weights,[], loss)\n",
    "netG_train = K.function([noisev], [loss], training_updates)\n",
    "\n",
    "fixed_noise = np.random.normal(size=(batchSize, nz)).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70171 images belonging to 1 classes.\n",
      "[0] Loss_D: 0.027011 Loss_G: 0.008974 Loss_D_real: 0.018254 Loss_D_fake -0.008756\n",
      "[1] Loss_D: 0.034944 Loss_G: 0.006396 Loss_D_real: 0.029456 Loss_D_fake -0.005488\n",
      "[2] Loss_D: 0.049948 Loss_G: 0.005329 Loss_D_real: 0.046209 Loss_D_fake -0.003738\n",
      "[3] Loss_D: 0.069570 Loss_G: 0.005744 Loss_D_real: 0.064861 Loss_D_fake -0.004709\n",
      "[4] Loss_D: 0.095300 Loss_G: 0.007880 Loss_D_real: 0.089106 Loss_D_fake -0.006194\n",
      "[5] Loss_D: 0.122936 Loss_G: 0.013796 Loss_D_real: 0.111641 Loss_D_fake -0.011295\n",
      "[6] Loss_D: 0.164566 Loss_G: 0.025128 Loss_D_real: 0.144489 Loss_D_fake -0.020077\n",
      "[7] Loss_D: 0.231617 Loss_G: 0.050456 Loss_D_real: 0.192197 Loss_D_fake -0.039419\n",
      "[8] Loss_D: 0.291975 Loss_G: 0.093455 Loss_D_real: 0.210657 Loss_D_fake -0.081318\n",
      "[9] Loss_D: 0.403776 Loss_G: 0.161213 Loss_D_real: 0.267334 Loss_D_fake -0.136442\n",
      "[10] Loss_D: 0.512341 Loss_G: 0.222676 Loss_D_real: 0.304137 Loss_D_fake -0.208204\n",
      "[11] Loss_D: 0.605474 Loss_G: 0.283612 Loss_D_real: 0.347717 Loss_D_fake -0.257757\n",
      "[12] Loss_D: 0.704881 Loss_G: 0.335840 Loss_D_real: 0.379938 Loss_D_fake -0.324943\n",
      "[13] Loss_D: 0.780012 Loss_G: 0.380252 Loss_D_real: 0.417908 Loss_D_fake -0.362105\n",
      "[14] Loss_D: 0.847699 Loss_G: 0.417684 Loss_D_real: 0.435495 Loss_D_fake -0.412204\n",
      "[15] Loss_D: 0.914265 Loss_G: 0.448993 Loss_D_real: 0.471770 Loss_D_fake -0.442495\n",
      "[16] Loss_D: 0.970400 Loss_G: 0.475905 Loss_D_real: 0.501750 Loss_D_fake -0.468650\n",
      "[17] Loss_D: 1.024220 Loss_G: 0.505688 Loss_D_real: 0.526625 Loss_D_fake -0.497594\n",
      "[18] Loss_D: 1.070866 Loss_G: 0.527513 Loss_D_real: 0.547426 Loss_D_fake -0.523440\n",
      "[19] Loss_D: 1.102798 Loss_G: 0.547918 Loss_D_real: 0.557388 Loss_D_fake -0.545410\n",
      "[20] Loss_D: 1.141488 Loss_G: 0.570706 Loss_D_real: 0.573261 Loss_D_fake -0.568227\n",
      "[21] Loss_D: 1.185310 Loss_G: 0.594181 Loss_D_real: 0.595221 Loss_D_fake -0.590089\n",
      "[22] Loss_D: 1.229650 Loss_G: 0.613909 Loss_D_real: 0.620791 Loss_D_fake -0.608859\n",
      "[23] Loss_D: 1.260679 Loss_G: 0.631191 Loss_D_real: 0.633259 Loss_D_fake -0.627420\n",
      "[24] Loss_D: 1.291665 Loss_G: 0.649607 Loss_D_real: 0.647227 Loss_D_fake -0.644438\n",
      "[25] Loss_D: 1.325308 Loss_G: 0.665654 Loss_D_real: 0.663174 Loss_D_fake -0.662134\n",
      "[26] Loss_D: 1.352628 Loss_G: 0.679537 Loss_D_real: 0.675784 Loss_D_fake -0.676843\n",
      "[27] Loss_D: 1.376877 Loss_G: 0.690976 Loss_D_real: 0.687113 Loss_D_fake -0.689764\n",
      "[28] Loss_D: 1.410179 Loss_G: 0.706503 Loss_D_real: 0.707075 Loss_D_fake -0.703104\n",
      "[29] Loss_D: 1.420834 Loss_G: 0.718644 Loss_D_real: 0.704512 Loss_D_fake -0.716322\n",
      "[30] Loss_D: 1.447309 Loss_G: 0.730669 Loss_D_real: 0.719085 Loss_D_fake -0.728224\n",
      "[31] Loss_D: 1.476399 Loss_G: 0.741935 Loss_D_real: 0.736615 Loss_D_fake -0.739784\n",
      "[32] Loss_D: 1.491064 Loss_G: 0.751849 Loss_D_real: 0.741846 Loss_D_fake -0.749218\n",
      "[33] Loss_D: 1.526423 Loss_G: 0.762128 Loss_D_real: 0.766617 Loss_D_fake -0.759805\n",
      "[34] Loss_D: 1.534332 Loss_G: 0.771817 Loss_D_real: 0.764571 Loss_D_fake -0.769761\n",
      "[35] Loss_D: 1.542777 Loss_G: 0.778867 Loss_D_real: 0.765558 Loss_D_fake -0.777219\n",
      "[36] Loss_D: 1.570578 Loss_G: 0.787180 Loss_D_real: 0.785291 Loss_D_fake -0.785287\n",
      "[37] Loss_D: 1.580164 Loss_G: 0.793188 Loss_D_real: 0.789231 Loss_D_fake -0.790932\n",
      "[38] Loss_D: 1.596287 Loss_G: 0.798314 Loss_D_real: 0.799093 Loss_D_fake -0.797194\n",
      "[39] Loss_D: 1.599053 Loss_G: 0.801840 Loss_D_real: 0.798102 Loss_D_fake -0.800951\n",
      "[40] Loss_D: 1.605475 Loss_G: 0.807716 Loss_D_real: 0.799507 Loss_D_fake -0.805967\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=20,rescale=1./255)\n",
    "\n",
    "train_generate = datagen.flow_from_directory(\"faces/\", target_size=(96,96), batch_size=64, \n",
    "                                                shuffle=True, class_mode=None, save_format='jpg')\n",
    "\n",
    "step = 0\n",
    "for step in range(100000):   \n",
    "    \n",
    "    for _ in range(5):\n",
    "        real_data = (np.array(train_generate.next())*2-1)\n",
    "        noise = np.random.normal(size=(batchSize, nz))\n",
    "        errD_real, errD_fake  = netD_train([real_data, noise])\n",
    "        errD = errD_real - errD_fake\n",
    "        netD_clamp([])\n",
    "    \n",
    "    noise = np.random.normal(size=(batchSize, nz))  \n",
    "    errG, = netG_train([noise])    \n",
    "    print('[%d] Loss_D: %f Loss_G: %f Loss_D_real: %f Loss_D_fake %f' % (step, errD, errG, errD_real, errD_fake))\n",
    "            \n",
    "    if step%1000==0:\n",
    "        netD.save(\"discriminator.h5\")\n",
    "        netG.save(\"generate.h5\")\n",
    "        fake = netG.predict(fixed_noise)\n",
    "        display_grid = np.zeros((8*96,8*96,3))\n",
    "        \n",
    "        for j in range(int(64/8)):\n",
    "            for k in range(int(64/8)):\n",
    "                display_grid[j*96:(j+1)*96,k*96:(k+1)*96,:] = fake[k+8*j]\n",
    "        img_save_path = os.path.join(os.getcwd(),\"saved/img/{}.png\".format(step))\n",
    "        scipy.misc.imsave(img_save_path, display_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
